{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Multi-label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s):<br>\n",
    "<b>Kunal J. Tolani</b> &\n",
    "<b>Chirag K. Shah</b><br>\n",
    "Student Number(s):<br>\n",
    "<b>19200153</b> &\n",
    "<b>19200072</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, make_scorer, f1_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import clone\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load the Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>...</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.170975</td>\n",
       "      <td>-0.156748</td>\n",
       "      <td>-0.142151</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>0.026851</td>\n",
       "      <td>0.197719</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.103956</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-0.098986</td>\n",
       "      <td>-0.054501</td>\n",
       "      <td>-0.007970</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>-0.030580</td>\n",
       "      <td>-0.077933</td>\n",
       "      <td>-0.080529</td>\n",
       "      <td>-0.016267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.509949</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.293799</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.006411</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-0.040666</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119092</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>-0.051467</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>0.079438</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>-0.069483</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-0.048207</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.064456</td>\n",
       "      <td>-0.133387</td>\n",
       "      <td>0.068878</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2412</td>\n",
       "      <td>-0.119784</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.123645</td>\n",
       "      <td>-0.015513</td>\n",
       "      <td>-0.059683</td>\n",
       "      <td>0.091032</td>\n",
       "      <td>-0.043302</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>-0.071498</td>\n",
       "      <td>0.182709</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2413</td>\n",
       "      <td>0.085327</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.052618</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2414</td>\n",
       "      <td>0.082526</td>\n",
       "      <td>-0.095571</td>\n",
       "      <td>-0.022019</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>0.041084</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2415</td>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>-0.009457</td>\n",
       "      <td>-0.058930</td>\n",
       "      <td>-0.041224</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.117717</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>-0.085563</td>\n",
       "      <td>0.136649</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2416</td>\n",
       "      <td>-0.171578</td>\n",
       "      <td>-0.066536</td>\n",
       "      <td>0.168206</td>\n",
       "      <td>0.246831</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>-0.088908</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>-0.280230</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       "0     0.004168 -0.170975 -0.156748 -0.142151  0.058781  0.026851  0.197719   \n",
       "1    -0.103956  0.011879 -0.098986 -0.054501 -0.007970  0.049113 -0.030580   \n",
       "2     0.509949  0.401709  0.293799  0.087714  0.011686 -0.006411 -0.006255   \n",
       "3     0.119092  0.004412 -0.002262  0.072254  0.044512 -0.051467  0.074686   \n",
       "4     0.042037  0.007054 -0.069483  0.081015 -0.048207  0.089446 -0.004947   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2412 -0.119784  0.001259 -0.123645 -0.015513 -0.059683  0.091032 -0.043302   \n",
       "2413  0.085327  0.058590  0.085268 -0.020897  0.068972  0.030125  0.078056   \n",
       "2414  0.082526 -0.095571 -0.022019 -0.046793 -0.038360  0.041084  0.056509   \n",
       "2415 -0.130830  0.008868 -0.009457 -0.058930 -0.041224  0.042269  0.117717   \n",
       "2416 -0.171578 -0.066536  0.168206  0.246831  0.079555  0.016528 -0.088908   \n",
       "\n",
       "          Att8      Att9     Att10  ...  Class5  Class6  Class7  Class8  \\\n",
       "0     0.041850  0.066938 -0.056617  ...       0       0       1       1   \n",
       "1    -0.077933 -0.080529 -0.016267  ...       0       0       0       0   \n",
       "2     0.013646 -0.040666 -0.024447  ...       0       0       0       0   \n",
       "3    -0.007670  0.079438  0.062184  ...       0       0       0       0   \n",
       "4     0.064456 -0.133387  0.068878  ...       1       1       0       0   \n",
       "...        ...       ...       ...  ...     ...     ...     ...     ...   \n",
       "2412  0.229219 -0.071498  0.182709  ...       0       0       0       0   \n",
       "2413  0.011346  0.052618  0.066093  ...       0       0       0       0   \n",
       "2414  0.011749 -0.029657 -0.012198  ...       0       1       1       1   \n",
       "2415  0.037388 -0.085563  0.136649  ...       0       0       0       0   \n",
       "2416 -0.212926 -0.280230 -0.187064  ...       0       0       0       0   \n",
       "\n",
       "      Class9  Class10  Class11  Class12  Class13  Class14  \n",
       "0          0        0        0        1        1        0  \n",
       "1          0        0        0        0        0        0  \n",
       "2          0        0        0        1        1        0  \n",
       "3          0        0        0        0        0        0  \n",
       "4          0        0        0        0        0        0  \n",
       "...      ...      ...      ...      ...      ...      ...  \n",
       "2412       0        0        0        0        0        0  \n",
       "2413       0        0        0        1        1        0  \n",
       "2414       0        0        0        1        1        0  \n",
       "2415       0        0        0        1        1        0  \n",
       "2416       0        0        0        1        1        0  \n",
       "\n",
       "[2417 rows x 117 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast = pd.read_csv('yeast.csv')\n",
    "yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yeast.iloc[:, 0:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "      <th>Class4</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2412</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2413</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2416</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class1  Class2  Class3  Class4  Class5  Class6  Class7  Class8  Class9  \\\n",
       "0          0       0       0       0       0       0       1       1       0   \n",
       "1          0       0       1       1       0       0       0       0       0   \n",
       "2          0       1       1       0       0       0       0       0       0   \n",
       "3          0       0       1       1       0       0       0       0       0   \n",
       "4          0       0       1       1       1       1       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2412       0       1       1       0       0       0       0       0       0   \n",
       "2413       1       1       0       0       0       0       0       0       0   \n",
       "2414       0       0       0       0       0       1       1       1       0   \n",
       "2415       0       0       0       0       0       0       0       0       0   \n",
       "2416       0       1       1       0       0       0       0       0       0   \n",
       "\n",
       "      Class10  Class11  Class12  Class13  Class14  \n",
       "0           0        0        1        1        0  \n",
       "1           0        0        0        0        0  \n",
       "2           0        0        1        1        0  \n",
       "3           0        0        0        0        0  \n",
       "4           0        0        0        0        0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "2412        0        0        0        0        0  \n",
       "2413        0        0        1        1        0  \n",
       "2414        0        0        1        1        0  \n",
       "2415        0        0        1        1        0  \n",
       "2416        0        0        1        1        0  \n",
       "\n",
       "[2417 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = yeast.iloc[:,-14:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom accuracy score based on hamming loss implementation\n",
    "\n",
    "def get_accuracy_score(y_test,y_pred):\n",
    "    \n",
    "    if 'numpy' not in str(type(y_pred)):\n",
    "        y_pred = y_pred.to_numpy()\n",
    "        \n",
    "    if 'numpy' not in str(type(y_test)):\n",
    "        y_test = y_test.to_numpy()\n",
    "    \n",
    "    \n",
    "    assert(y_test.shape == y_pred.shape)\n",
    "    \n",
    "    if y_pred.shape[1] <= 5: #For a smaller number of labels, a ratio of half the labels being correct is good enough\n",
    "        ratio = 0.5\n",
    "    else:\n",
    "        ratio = 0.7 #For a number of labels, at least 70% of the predicted labels must be correct\n",
    "    \n",
    "    acc_rows = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        acc_rows.append(np.count_nonzero(y_test[i]==y_pred[i]))\n",
    "#         acc_rows.append(np.count_nonzero(y_test.iloc[i,:].values==y_pred.iloc[i,:].values)) #Count the number of matches\n",
    "        \n",
    "    acc_rows = [1 if x/y_pred.shape[1] >= ratio else 0 for x in acc_rows] #1 if ratio of match in a row is greater than ratio, else 0\n",
    "    return sum(acc_rows)/len(acc_rows) # Mean accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Binary Relevance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, base_model=LogisticRegression()):\n",
    "        self.base_model = base_model #base model - by default logistic regression\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model_list_ = []\n",
    "        for column in y:  #For every label in y, fit the model independently\n",
    "            clf = clone(self.base_model) #Clone the base model to avoid shallow copy\n",
    "            A,b = check_X_y(X,y[column])\n",
    "            clf.fit(A,b) #fit the model for the particular label value\n",
    "            self.model_list_.append(clf) #Add the model to the saved model list\n",
    "            \n",
    "    def predict(self,X):\n",
    "        check_is_fitted(self, ['model_list_']) \n",
    "        X = check_array(X)\n",
    "        y_pred = pd.DataFrame() #Create a dataframe to save predictions\n",
    "        i = 1\n",
    "        for model in self.model_list_: #Make predictions for each label, using the corresponding mdodel\n",
    "            y_pred_class = model.predict(X) \n",
    "            y_pred[i] = y_pred_class #Add current prediction to dataframe\n",
    "            i+=1\n",
    "        return y_pred.to_numpy() #return final predictions\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        check_is_fitted(self, ['model_list_']) #Check if model list is present\n",
    "        X = check_array(X)\n",
    "        y_pred = pd.DataFrame()\n",
    "        i = 1\n",
    "        for model in self.model_list_:\n",
    "            y_pred_class = model.predict_proba(X) #Call predict_proba of the each base model\n",
    "            y_pred[i] = [one_prob[1] for one_prob in y_pred_class] #Add the probability of 1 to the dataframe\n",
    "            i+=1\n",
    "        return y_pred.to_numpy() #return final probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binclf = BinaryRelevanceClassifier(base_model=RandomForestClassifier())\n",
    "binclf.fit(X_train,y_train)\n",
    "y_pred = binclf.predict(X_test) # Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8140495867768595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3539791385313155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_accuracy_score(y_test,y_pred)) # Default accuracy score not used because it performs exact matching\n",
    "display(f1_score(y_test, y_pred, average='macro')) # F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=BinaryRelevanceClassifier(base_model=LogisticRegression(C=1.0,\n",
       "                                                                               class_weight=None,\n",
       "                                                                               dual=False,\n",
       "                                                                               fit_intercept=True,\n",
       "                                                                               intercept_scaling=1,\n",
       "                                                                               l1_ratio=None,\n",
       "                                                                               max_iter=100,\n",
       "                                                                               multi_class='auto',\n",
       "                                                                               n_jobs=None,\n",
       "                                                                               penalty='l2',\n",
       "                                                                               random_state=None,\n",
       "                                                                               solver='lbfgs',\n",
       "                                                                               tol=0.0001,\n",
       "                                                                               verbose=0,\n",
       "                                                                               warm_start=False)),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             pa...\n",
       "                                                            class_weight=None,\n",
       "                                                            dual=False,\n",
       "                                                            fit_intercept=True,\n",
       "                                                            intercept_scaling=1,\n",
       "                                                            l1_ratio=None,\n",
       "                                                            max_iter=100,\n",
       "                                                            multi_class='auto',\n",
       "                                                            n_jobs=None,\n",
       "                                                            penalty='l2',\n",
       "                                                            random_state=None,\n",
       "                                                            solver='lbfgs',\n",
       "                                                            tol=0.0001,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False)],\n",
       "                          'base_model__max_iter': [1000, 20000, 40000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(get_accuracy_score), verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search with multiple base estimators\n",
    "params_grid = [\n",
    "    {\n",
    "                'base_model':[DecisionTreeClassifier()],\n",
    "                'base_model__criterion': [\"gini\", \"entropy\"],\n",
    "                'base_model__max_depth': [None, 10, 15, 20, 50],\n",
    "                'base_model__min_samples_split':[2,8,10]\n",
    "                },\n",
    "                {\n",
    "                'base_model': [RandomForestClassifier()],\n",
    "                'base_model__min_samples_split':[2,8,10],\n",
    "                'base_model__n_estimators':[100,500],\n",
    "                },\n",
    "                {\n",
    "                'base_model':[LogisticRegression()],\n",
    "                'base_model__max_iter':[1000,20000,40000]\n",
    "                }\n",
    "              ]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(BinaryRelevanceClassifier(), params_grid, verbose = 2, n_jobs=-1, scoring=make_scorer(get_accuracy_score))\n",
    "my_tuned_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=8,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'base_model__min_samples_split': 8, 'base_model__n_estimators': 500}\n",
      "0.835010734670367\n"
     ]
    }
   ],
   "source": [
    "#Finding our best params and score\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the Binary Relevance Algorithm with Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "class BinaryRelevanceClassifierUnderSampled(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, base_model=LogisticRegression()):\n",
    "        self.base_model = base_model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.model_list_ = []\n",
    "        for column in y: #For every label in y, fit the model independently\n",
    "            X_copy = X.copy()\n",
    "            clf = clone(self.base_model) #Clone the base model to avoid shallow copy\n",
    "            concat_x_y = X_copy.join(y[column]) #Concat X and the label to perform undersampling\n",
    "            label_0, label_1 = sum(y[column]==0), sum(y[column])\n",
    "            \n",
    "            ratio = label_1/label_0 #Check the ratio of 1s to 0s in a target\n",
    "            \n",
    "            '''Here, we undersample only when the difference between 1 and 0 is quite large, \n",
    "            that is if the number of the majority class is more than double the number of the minority class'''\n",
    "            \n",
    "            if ratio < 0.5: \n",
    "                xy_label_1 = concat_x_y[concat_x_y[column]==1]\n",
    "                xy_label_0 = concat_x_y[concat_x_y[column]==0].sample(label_1) # Undersample using pd.sample on label 0\n",
    "                concat_x_y = pd.concat([xy_label_0, xy_label_1], axis=0)\n",
    "                \n",
    "            elif ratio >= 2:\n",
    "                \n",
    "                xy_label_1 = concat_x_y[concat_x_y[column]==1].sample(label_0) # Undersample using pd.sample on label 1\n",
    "                xy_label_0 = concat_x_y[concat_x_y[column]==0]\n",
    "                concat_x_y = pd.concat([xy_label_0, xy_label_1], axis=0)              \n",
    "            \n",
    "            #Separate concatenated dataset into X and y\n",
    "            X_copy = concat_x_y.iloc[:,:-1]\n",
    "            y_column = concat_x_y.iloc[:,-1]\n",
    "            \n",
    "            #Fit the model\n",
    "            A,b = check_X_y(X_copy,y_column)\n",
    "            clf.fit(A,b)\n",
    "            self.model_list_.append(clf) # Append model to model list\n",
    "            \n",
    "    def predict(self,X):\n",
    "        check_is_fitted(self, ['model_list_']) # Check if the model list is present\n",
    "        X = check_array(X)\n",
    "        y_pred = pd.DataFrame() # Create a dataframe to save predictions\n",
    "        i = 1\n",
    "        for model in self.model_list_: # Make predictions for each label, using the corresponding mdodel\n",
    "            y_pred_class = model.predict(X) \n",
    "            y_pred[i] = y_pred_class # Add current prediction to dataframe\n",
    "            i+=1\n",
    "        return y_pred.to_numpy() # Return predictions\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        check_is_fitted(self, ['model_list_']) #Check if the model list is present\n",
    "        X = check_array(X)\n",
    "        y_pred = pd.DataFrame()\n",
    "        i = 1\n",
    "        for model in self.model_list_:\n",
    "            y_pred_class = model.predict_proba(X) #Call predict_proba of the each base model\n",
    "            y_pred[i] = [one_prob[1] for one_prob in y_pred_class] #Add the probabilities of 1 to the dataframe\n",
    "            i+=1\n",
    "        return y_pred.to_numpy() #return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binclf_u = BinaryRelevanceClassifierUnderSampled(base_model=RandomForestClassifier())\n",
    "binclf_u.fit(X_train,y_train)\n",
    "y_pred_un = binclf_u.predict(X_test) # Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4628099173553719"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.44454831468970496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_accuracy_score(y_test,y_pred_un))\n",
    "display(f1_score(y_pred_un,y_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=BinaryRelevanceClassifierUnderSampled(base_model=LogisticRegression(C=1.0,\n",
       "                                                                                           class_weight=None,\n",
       "                                                                                           dual=False,\n",
       "                                                                                           fit_intercept=True,\n",
       "                                                                                           intercept_scaling=1,\n",
       "                                                                                           l1_ratio=None,\n",
       "                                                                                           max_iter=100,\n",
       "                                                                                           multi_class='auto',\n",
       "                                                                                           n_jobs=None,\n",
       "                                                                                           penalty='l2',\n",
       "                                                                                           random_state=None,\n",
       "                                                                                           solver='lbfgs',\n",
       "                                                                                           tol=0.0001,\n",
       "                                                                                           verbose=0,\n",
       "                                                                                           warm_start=False)),\n",
       "             iid='deprecated',...\n",
       "                                                            class_weight=None,\n",
       "                                                            dual=False,\n",
       "                                                            fit_intercept=True,\n",
       "                                                            intercept_scaling=1,\n",
       "                                                            l1_ratio=None,\n",
       "                                                            max_iter=100,\n",
       "                                                            multi_class='auto',\n",
       "                                                            n_jobs=None,\n",
       "                                                            penalty='l2',\n",
       "                                                            random_state=None,\n",
       "                                                            solver='lbfgs',\n",
       "                                                            tol=0.0001,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False)],\n",
       "                          'base_model__max_iter': [1000, 20000, 40000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(get_accuracy_score), verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search with multiple base estimators\n",
    "params_grid = [\n",
    "    {\n",
    "                'base_model':[DecisionTreeClassifier()],\n",
    "                'base_model__criterion': [\"gini\", \"entropy\"],\n",
    "                'base_model__max_depth': [None, 10, 15, 20, 50],\n",
    "                'base_model__min_samples_split':[2,8,10]\n",
    "                },\n",
    "                {\n",
    "                'base_model': [RandomForestClassifier()],\n",
    "                'base_model__min_samples_split':[2,8,10],\n",
    "                'base_model__n_estimators':[100,500],\n",
    "                },\n",
    "                {\n",
    "                'base_model':[LogisticRegression()],\n",
    "                'base_model__max_iter':[1000,20000,40000]\n",
    "                }\n",
    "              ]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(BinaryRelevanceClassifierUnderSampled(), params_grid, verbose = 2, n_jobs=-1, scoring=make_scorer(get_accuracy_score))\n",
    "my_tuned_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'base_model__min_samples_split': 2, 'base_model__n_estimators': 100}\n",
      "0.44294042694314995\n"
     ]
    }
   ],
   "source": [
    "#Finding our best params and score\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Binary Relevance Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Without Under Sampling\n",
      "\n",
      "Accuracy: 0.8168044077134986\n",
      "F1 Score: 0.3476054358289854\n",
      "\n",
      "\n",
      "With Under Sampling\n",
      "Accuracy: 0.44352617079889806\n",
      "F1 Score: 0.44166645546409666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the best model of binary relevance undersampled for evaluation across models\n",
    "\n",
    "classifier = my_tuned_model.best_estimator_.base_model\n",
    "    \n",
    "print(classifier)\n",
    "print(\"Without Under Sampling\")\n",
    "binclf = BinaryRelevanceClassifier(base_model=classifier)\n",
    "binclf.fit(X_train,y_train)\n",
    "y_pred = binclf.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy: \" + str(get_accuracy_score(y_test,y_pred)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"\\n\") \n",
    "print(\"With Under Sampling\")\n",
    "\n",
    "binclf_u = BinaryRelevanceClassifierUnderSampled(base_model=classifier)\n",
    "binclf_u.fit(X_train,y_train)\n",
    "y_pred_un = binclf_u.predict(X_test)\n",
    "print(\"Accuracy: \" + str(get_accuracy_score(y_test,y_pred_un)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred_un, average='macro')))\n",
    "print(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Implement the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, base_model=LogisticRegression(), order = None, undersample=False):\n",
    "        self.base_model = base_model # The base estimator\n",
    "        self.order = order # Order of labels in which the labels are to be sent to the classifier\n",
    "        self.undersample = undersample # Whether or not to undersample\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_cpy = X.copy()\n",
    "        y_cpy = y.copy()\n",
    "        self.order_shuffle = None\n",
    "        self.base_order = list(range(len(y.columns)))\n",
    "        \n",
    "        if self.order is None:\n",
    "            self.order_shuffle = list(range(len(y_cpy.columns))) # Same order as input\n",
    "            \n",
    "        elif self.order == 'random':\n",
    "            self.order_shuffle = list(range(len(y_cpy.columns))) # Random label order\n",
    "            random.shuffle(self.order_shuffle)\n",
    "            print(self.order_shuffle)\n",
    "            \n",
    "        else:\n",
    "            if len(self.order) == len(y.columns) and all(isinstance(item, int) for item in self.order):\n",
    "                self.order_shuffle = self.order # Label order given by user\n",
    "        \n",
    "        y_cpy = y_cpy.iloc[:,self.order_shuffle] # Shuffle y according to label order\n",
    "        \n",
    "        \n",
    "        self.model_list_ = []\n",
    "        for column in y_cpy:\n",
    "            X_cpy.reset_index(drop=True, inplace=True)\n",
    "            y_cpy.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            X_copy = X_cpy.copy()\n",
    "            \n",
    "            if self.undersample:\n",
    "                concat_x_y = X_copy.join(y_cpy[column]) #Concat X and the label to perform undersampling\n",
    "                label_0, label_1 = sum(y_cpy[column]==0), sum(y_cpy[column])\n",
    "\n",
    "                ratio = label_1/label_0 #Check the ratio of 1s to 0s in a target\n",
    "\n",
    "                '''Here, we undersample only when the difference between 1 and 0 is quite large, \n",
    "                that is if the number of the majority class is more than double the number of the minority class'''\n",
    "\n",
    "                if ratio < 0.5: # Undersample using pd.sample on label 0\n",
    "                    xy_label_1 = concat_x_y[concat_x_y[column]==1]\n",
    "                    xy_label_0 = concat_x_y[concat_x_y[column]==0].sample(label_1)\n",
    "                    concat_x_y = pd.concat([xy_label_0, xy_label_1], axis=0)\n",
    "\n",
    "                elif ratio >= 2: # Undersample using pd.sample on label 1\n",
    "                    xy_label_1 = concat_x_y[concat_x_y[column]==1].sample(label_0) \n",
    "                    xy_label_0 = concat_x_y[concat_x_y[column]==0]\n",
    "                    concat_x_y = pd.concat([xy_label_0, xy_label_1], axis=0)              \n",
    "\n",
    "                #Separate concatenated dataset into X and y\n",
    "                X_copy = concat_x_y.iloc[:,:-1]\n",
    "                y_column = concat_x_y.iloc[:,-1]\n",
    "\n",
    "            else:\n",
    "                y_column = y_cpy[column]\n",
    "                \n",
    "            clf = clone(self.base_model)\n",
    "            A,b = check_X_y(X_copy, y_column)\n",
    "            clf.fit(A,b)  # Fit model to the (undersampled if true) dataset\n",
    "            self.model_list_.append(clf)   # Append model to list\n",
    "            y_col = pd.DataFrame(y_cpy[column])\n",
    "            X_cpy = pd.concat([X_cpy, y_col], axis=1)  # Concatenate current label to X\n",
    "            \n",
    "            \n",
    "    def predict(self,X):\n",
    "        X_cpy = X.copy()\n",
    "        X_cpy.reset_index(drop=True, inplace=True)\n",
    "        check_is_fitted(self, ['model_list_']) # Check if the model list is present\n",
    "        y_pred = pd.DataFrame() # Create a dataframe to save predictions\n",
    "        i = 0\n",
    "        for model in self.model_list_: # Make predictions for each label, using the corresponding mdodel\n",
    "            X_cpy = check_array(X_cpy)\n",
    "            y_pred_class = model.predict(X_cpy) # Predict current label\n",
    "            y_pred[self.order_shuffle[i]] = y_pred_class # Save the predicted class according to our label order\n",
    "            \n",
    "            X_cpy = np.column_stack((X_cpy, y_pred_class)) # Append the predicted column to X test\n",
    "            i+=1\n",
    "            \n",
    "        y_pred = y_pred.loc[:,self.base_order] # Return according to original order\n",
    "        return y_pred.to_numpy() # Return as numpy array\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        X_cpy = X.copy()\n",
    "        X_cpy.reset_index(drop=True, inplace=True)\n",
    "        check_is_fitted(self, ['model_list_']) #Check if the model list is present\n",
    "        y_pred = pd.DataFrame() # Create a dataframe to save predictions\n",
    "        i = 0\n",
    "        for model in self.model_list_: # Make prediction probabilities for each label, using the corresponding mdodel\n",
    "            X_cpy = check_array(X_cpy)\n",
    "            y_pred_class = model.predict(X_cpy) # Predict current label\n",
    "            y_pred_class_proba = model.predict_proba(X_cpy) # Predict probabilties using current model\n",
    "            y_pred[self.order_shuffle[i]] = [one_prob[1] for one_prob in y_pred_class_proba] # Save the probabilities of 1 according to our label order\n",
    "            X_cpy = np.column_stack((X_cpy, y_pred_class)) # Append prediction to X test\n",
    "            i+=1\n",
    "        y_pred = y_pred.loc[:,self.base_order] # Return probabilities according to original order\n",
    "        return y_pred.to_numpy() # Return as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_chain = ClassifierChains(base_model=RandomForestClassifier(),undersample=False)\n",
    "class_chain.fit(X_train,y_train)\n",
    "y_pred_cc = class_chain.predict(X_test) # Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471074380165289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3763361468097855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_accuracy_score(y_test,y_pred_cc))\n",
    "display(f1_score(y_pred_cc,y_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed: 11.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 10, 1, 8, 5, 4, 11, 2, 13, 3, 0, 12, 9, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=ClassifierChains(base_model=LogisticRegression(C=1.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      dual=False,\n",
       "                                                                      fit_intercept=True,\n",
       "                                                                      intercept_scaling=1,\n",
       "                                                                      l1_ratio=None,\n",
       "                                                                      max_iter=100,\n",
       "                                                                      multi_class='auto',\n",
       "                                                                      n_jobs=None,\n",
       "                                                                      penalty='l2',\n",
       "                                                                      random_state=None,\n",
       "                                                                      solver='lbfgs',\n",
       "                                                                      tol=0.0001,\n",
       "                                                                      verbose=0,\n",
       "                                                                      warm_start=False),\n",
       "                                        order=None, undersample=False),\n",
       "             iid='depr...\n",
       "                                                            class_weight=None,\n",
       "                                                            dual=False,\n",
       "                                                            fit_intercept=True,\n",
       "                                                            intercept_scaling=1,\n",
       "                                                            l1_ratio=None,\n",
       "                                                            max_iter=100,\n",
       "                                                            multi_class='auto',\n",
       "                                                            n_jobs=None,\n",
       "                                                            penalty='l2',\n",
       "                                                            random_state=None,\n",
       "                                                            solver='lbfgs',\n",
       "                                                            tol=0.0001,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False)],\n",
       "                          'base_model__max_iter': [1000, 20000, 40000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(get_accuracy_score), verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing grid search with different base estimators\n",
    "params_grid = [\n",
    "    {\n",
    "                'base_model':[DecisionTreeClassifier()],\n",
    "                'base_model__criterion': [\"gini\", \"entropy\"],\n",
    "                'base_model__max_depth': [None, 10, 15, 20, 50],\n",
    "                'base_model__min_samples_split':[2,8,10]\n",
    "                },\n",
    "                {\n",
    "                'base_model': [RandomForestClassifier()],\n",
    "                'base_model__min_samples_split':[2,10],\n",
    "                'base_model__n_estimators':[100,500],\n",
    "                'order':['random','random','random','random']\n",
    "                },\n",
    "                {\n",
    "                'base_model':[LogisticRegression()],\n",
    "                'base_model__max_iter':[1000,20000,40000]\n",
    "                }\n",
    "              ]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ClassifierChains(), params_grid, verbose = 10, n_jobs=-1, scoring=make_scorer(get_accuracy_score))\n",
    "my_tuned_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'base_model__min_samples_split': 2, 'base_model__n_estimators': 500, 'order': 'random'}\n",
      "0.842106089961774\n"
     ]
    }
   ],
   "source": [
    "#Finding our best params and score\n",
    "print(my_tuned_model.best_params_)\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Monte Carlo Methods for finding best label orders for Classifier Chains\n",
    "Based on (Read, Martino and Luengo, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteClassifierChains(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, base_model=LogisticRegression()):\n",
    "        self.base_model = base_model\n",
    "        self.labels_id_dict = {}\n",
    "        self.best_label_order = []\n",
    "        self.original_label_order = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, train_size = 0.7)\n",
    "        \n",
    "        labels = list(y.columns)\n",
    "        self.original_label_order = list(y.columns)\n",
    "        replace_set = set()\n",
    "        list_labels = []\n",
    "        payoff_list = []\n",
    "    \n",
    "        #Swapper function for swapping two randomly selected labels\n",
    "        def swapper(labels, weights=None):\n",
    "            a, b = np.random.choice(labels, size=2, p=weights, replace=False) # Swap two labels according to the probabilities\n",
    "            m = labels.index(a)\n",
    "            n = labels.index(b)\n",
    "            labels[m] = b\n",
    "            labels[n] = a\n",
    "            return labels, a, b #Return the label list, and the swapped labels\n",
    "        \n",
    "        # Payoff returns the accuracy on a validation set\n",
    "        def payoff(list_order, X_val, y_test):\n",
    "        \n",
    "            X_val.reset_index(drop=True, inplace=True) # Reset index - for concatenation later\n",
    "            y_pred_val_df = pd.DataFrame()\n",
    "            \n",
    "            for i in range(len(list_order)):\n",
    "\n",
    "                try:\n",
    "                    clf = [key for key, value in self.labels_id_dict.items() if value == list_order[:i+1]][0]            \n",
    "                except IndexError:\n",
    "                    return float('inf') #Return infinity is label order not found\n",
    "\n",
    "                y_pred_val = clf.predict(X_val)\n",
    "                X_val = np.column_stack((X_val, y_pred_val))\n",
    "                y_pred_val_df[list_order[i]] = y_pred_val\n",
    "\n",
    "            return get_accuracy_score(y_test, y_pred_val_df)\n",
    "        \n",
    "\n",
    "        count = 0 #Count iterations\n",
    "        weights = [1/len(labels) for i in labels] #Probability weights for labels\n",
    "        \n",
    "        while count < 100:\n",
    "        \n",
    "\n",
    "            if count >= 20:  #After 20 iterations, keep updating probabilities according to position in index\n",
    "                beta = 0.5\n",
    "                t = count\n",
    "                weights = [(1/len(labels))**(beta*t/(labels.index(i)+1)) for i in labels]\n",
    "                weights = [float(i)/sum(weights) for i in weights]    \n",
    "            \n",
    "            X_cpy = X_train.copy()\n",
    "            y_cpy = y_train.copy()\n",
    "            X_cpy.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "            label_list_for = []\n",
    "            l,p,q = swapper(labels, weights)\n",
    "            if p in replace_set and q in replace_set:   #Swap only if both p and q have not already been swapped\n",
    "                    continue\n",
    "            \n",
    "            y_cpy = y_cpy.loc[:,l]\n",
    "            index_p = l.index(p)\n",
    "            index_q = l.index(q)\n",
    "            y_cpy.reset_index(drop=True, inplace=True)\n",
    "                    \n",
    "            \n",
    "            if count > 0:\n",
    "                smaller_index = index_p if index_p < index_q else index_q\n",
    "                X_cpy = pd.concat([X_cpy, y_cpy.iloc[:,:smaller_index]], axis=1)\n",
    "                y_cpy = y_cpy.iloc[:,smaller_index:]   \n",
    "                label_list_for.extend(l[:smaller_index])\n",
    "                \n",
    "                \n",
    "            for column in y_cpy:  #Classifier Chains\n",
    "                \n",
    "                label_list_for.append(column)\n",
    "                A,b = check_X_y(X_cpy, y_cpy[column])\n",
    "                clf = clone(self.base_model)\n",
    "                clf.fit(A,b)\n",
    "                self.labels_id_dict[clf] = label_list_for.copy()  #Adding list of labels to dict - with classifier id\n",
    "                b = pd.DataFrame(b)\n",
    "                                \n",
    "                X_cpy = pd.concat([X_cpy, b], axis=1)\n",
    "            \n",
    "            \n",
    "            curr_payoff = payoff(label_list_for, X_val, y_val)\n",
    "            \n",
    "            if curr_payoff == float('inf'):  #Handling the case when an exception is thrown in payoff\n",
    "                continue\n",
    "            if count == 0:\n",
    "                payoff_list.append(curr_payoff) #Initially not accounting for previous payoff\n",
    "            else:\n",
    "                if curr_payoff > payoff_list[-1]:\n",
    "                    payoff_list.append(curr_payoff)\n",
    "                else:\n",
    "                    count+=1\n",
    "                    continue   #Do not add to final list if payoff is worse\n",
    "\n",
    "            \n",
    "            #Add to set of swapped labels, and append a copy of the final list\n",
    "            replace_set.add(p)\n",
    "            replace_set.add(q)\n",
    "            list_labels.append(l.copy())\n",
    "            count += 1\n",
    "            labels = l\n",
    "            \n",
    "            #Clear replace set every 5 iterations\n",
    "            if count%5 == 0:\n",
    "                replace_set.clear()\n",
    "                \n",
    "        self.best_label_order = list_labels[-1]    #Final list in the list of labels is the best order\n",
    "        print(f\"Best order found: {self.best_label_order}\")\n",
    "                        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['best_label_order']) # Check if fitted - is best label order generated\n",
    "        \n",
    "        X_cpy = X.copy()\n",
    "        X_cpy.reset_index(drop=True, inplace=True)\n",
    "        y_pred_val_df = pd.DataFrame()\n",
    "        \n",
    "        for i in range(len(self.best_label_order)):\n",
    "            \n",
    "            X_cpy = check_array(X_cpy)\n",
    "            clf = [key for key, value in self.labels_id_dict.items() if value == self.best_label_order[:i+1]][0] # Find the model in dictionary according to current label\n",
    "            y_pred_val = clf.predict(X_cpy) # Make prediction\n",
    "            X_cpy = np.column_stack((X_cpy, y_pred_val)) # Add predicted value to X test\n",
    "            y_pred_val_df[self.best_label_order[i]] = y_pred_val # Add predicted value according to best label order\n",
    "        \n",
    "        y_pred_val_df = y_pred_val_df.loc[:,self.original_label_order] # Return predictions based on original order\n",
    "        \n",
    "        \n",
    "        return y_pred_val_df.to_numpy()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['best_label_order']) # Check if fitted - is best label order generated\n",
    "        \n",
    "        X_cpy = X.copy()\n",
    "        X_cpy.reset_index(drop=True, inplace=True)\n",
    "        y_pred_val_df = pd.DataFrame()\n",
    "        \n",
    "        for i in range(len(self.best_label_order)):\n",
    "            X_cpy = check_array(X_cpy)\n",
    "            clf = [key for key, value in self.labels_id_dict.items() if value == self.best_label_order[:i+1]][0]\n",
    "            y_pred_val = clf.predict_proba(X_cpy) # Generate probabilities for current label\n",
    "            X_cpy = np.column_stack((X_cpy, clf.predict(X_cpy))) # Add predicted value to X test\n",
    "            y_pred_val_df[self.best_label_order[i]] = [one_prob[1] for one_prob in y_pred_val] # Add predicted probabilities of 1 according to best label order\n",
    "\n",
    "         \n",
    "        y_pred_val_df = y_pred_val_df.loc[:,self.original_label_order] # Return probabilities based on original order\n",
    "        \n",
    "        return y_pred_val_df.to_numpy()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best order found: ['Class11', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6', 'Class7', 'Class8', 'Class9', 'Class10', 'Class1', 'Class12', 'Class13', 'Class14']\n"
     ]
    }
   ],
   "source": [
    "class_chain_mcc = MonteClassifierChains(base_model=my_tuned_model.best_estimator_.base_model)\n",
    "class_chain_mcc.fit(X_train,y_train)\n",
    "y_pred_mcc = class_chain_mcc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484848484848485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.36394890032715105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(get_accuracy_score(y_test,y_pred_mcc))\n",
    "display(f1_score(y_pred_mcc,y_test,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mcc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Evaluate the Performance of the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "BR Without Under Sampling\n",
      "\n",
      "Accuracy: 0.8264462809917356\n",
      "F1 Score: 0.3513414532898969\n",
      "\n",
      "\n",
      "BR With Under Sampling\n",
      "Accuracy: 0.47796143250688705\n",
      "F1 Score: 0.4496869252917108\n",
      "\n",
      "\n",
      "Classifier Chains Without Under Sampling\n",
      "Accuracy: 0.8443526170798898\n",
      "F1 Score: 0.3805947840081686\n",
      "\n",
      "\n",
      "Classifier Chains With Under Sampling\n",
      "Accuracy: 0.4972451790633609\n",
      "F1 Score: 0.4550165657812229\n",
      "\n",
      "\n",
      "Classifier Chains With Monte Carlo Method\n",
      "Accuracy: 0.8484848484848485\n",
      "F1 Score: 0.36394890032715105\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the best model for classifier chains for evaluation across models\n",
    "\n",
    "classifier = my_tuned_model.best_estimator_.base_model\n",
    "\n",
    "print(classifier)\n",
    "print(\"BR Without Under Sampling\")\n",
    "binclf = BinaryRelevanceClassifier(base_model=classifier)\n",
    "binclf.fit(X_train,y_train)\n",
    "y_pred = binclf.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy: \" + str(get_accuracy_score(y_test,y_pred)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"\\n\") \n",
    "\n",
    "print(\"BR With Under Sampling\")\n",
    "\n",
    "binclf_u = BinaryRelevanceClassifierUnderSampled(base_model=classifier)\n",
    "binclf_u.fit(X_train,y_train)\n",
    "y_pred_un = binclf_u.predict(X_test)\n",
    "print(\"Accuracy: \" + str(get_accuracy_score(y_test,y_pred_un)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred_un, average='macro')))\n",
    "print(\"\\n\") \n",
    "\n",
    "print(\"Classifier Chains Without Under Sampling\")\n",
    "\n",
    "class_cc_model = ClassifierChains(base_model=classifier, undersample=False)\n",
    "class_cc_model.fit(X_train,y_train)\n",
    "y_pred_cc = class_cc_model.predict(X_test)\n",
    "print(\"Accuracy: \" + str(get_accuracy_score(y_test,y_pred_cc)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred_cc, average='macro')))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classifier Chains With Under Sampling\")\n",
    "\n",
    "class_cc_model_un = ClassifierChains(base_model=classifier, undersample=True)\n",
    "class_cc_model_un.fit(X_train,y_train)\n",
    "y_pred_cc_un = class_cc_model_un.predict(X_test)\n",
    "print(\"Accuracy: \" + str(get_accuracy_score(y_test,y_pred_cc_un)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred_cc_un, average='macro')))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Classifier Chains With Monte Carlo Method\")\n",
    "\n",
    "print(\"Accuracy: \" + str(get_accuracy_score(y_test,y_pred_mcc)))\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred_mcc, average='macro')))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let,  \n",
    "A: Binary Relevance Classifier  \n",
    "B: Classifier Chains  \n",
    "C: Classifier Chains with Monte-Carlo  \n",
    "\n",
    "#### From the above experiments, we conclude:  \n",
    "* A without undersampling gives an accuracy of 83.19 which is better than A with undersampling. We undersample the majority class only when the difference between majority and miority is too large. Due to this, valid training samples maybe lost resulting in low accuracy scores.\n",
    "\n",
    "\n",
    "* A without undersampling has lower F1 scores becuase of high bias which corresponds to high precision and low recall values. However, after undersampling the bias is reduced to an extent which results in a better F1 score.\n",
    "\n",
    "\n",
    "* B works better than A because it takes label dependency into consideration whereas A doesn't. But B. has more complexity than A. because of the need to use the previous target labels for next predictions. The difference in terms of accuracy is not great and this comes as a surprise. So, for faster computation on Yeast Data, Binary Relevance Classifier can be an adequate method. \n",
    "\n",
    "* B with undersampling doesn't outperform than B without undersampling because of the same reasons mentioned in comparison of A.\n",
    "\n",
    "\n",
    "* Since, Classifier Chains takes previous labels and previous predictions in consideration while performing current predictions, label ordering is important. To find best label orderings, exhaustive search would be too computationally expensive. Hence, we adopted the Monte Carlo method C.\n",
    "\n",
    "\n",
    "* In this algorithm, we randomly swap two labels at every iteration and calculate payoff. The new label order is only accepted if the payoff at current instance is greater than payoff at previous instance. For a few initial iterations, swaps are performed uniformly accross all labels. However after fixed set of iterations, we assign higher weights to later labels so the entire label order wouldn't be retrained continously as we are freezing models and reusing them at each traversal across iterations. The best order found in the Monte Carlo method is not consistent across runs but is usually just one swap away from the original order.\n",
    "\n",
    "Performance - **C > B > A**\n",
    "\n",
    "Complexity - **C > B > A**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "\n",
    "Read, J., Martino, L. and Luengo, D. (2014). Efficient monte carlo methods for multi-dimensional learning with classifier chains. Pattern Recognition, [online] 47(3), pp.1535-1546. Available at: https://arxiv.org/pdf/1211.2190.pdf.  \n",
    "\n",
    "Read, J., Pfahringer, B., Holmes, G. and Frank, E. (2011). Classifier chains for multi-label classification. Machine Learning, [online] 85(3), pp.333-359. Available at: https://link.springer.com/content/pdf/10.1007/s10994-011-5256-5.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
